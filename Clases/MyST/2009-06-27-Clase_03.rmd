---
layout: post
title: "Clase 03"
main-class: 'clase'
permalink: /MuestreoySeriesdeTiempo/MyST:title.html
tags:

introduction: |
  Medidas de error o evaluación de los pronósticos.
header-includes:
   - \usepackage{amsmath,amssymb,amsthm,amsfonts}
   - \usepackage[sectionbib]{natbib}
   - \usepackage[hidelinks]{hyperref}
output:
  md_document:
    variant: markdown_strict+backtick_code_blocks+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash
    preserve_yaml: TRUE
always_allow_html: yes   
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_dir = "../../MuestreoySeriesdeTiempo/_posts/", output_format = "all"  ) })
bibliography: "../../referencias.bib"
csl: "../../apa.csl"
link-citations: yes
---

```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
## Global options
opts_chunk$set(echo=TRUE,
               cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               fig.path = paste0("../../MuestreoySeriesdeTiempo/images/", "Clase03"),
               cache.path = "../../MuestreoySeriesdeTiempo/cache/",
               cache = FALSE)
```

## Evaluación de los pronósticos 
Otro aspecto de suma importancia en los pronósticos, es evaluar la precisión o eficiencia del método de pronóstico empleado, y para ello, se emplean diferentes indicadores que permiten identificar qué tan acertado o cercano es el pronostico realizado respecto a su valor original.

Para aplicar dichos métodos, una alternativa es la implementación de un procedimiento conocido como *validación cruzada*, el cual consta de dividir el conjunto de observaciones de la serie en dos grupos. El primer grupo estará dado por las observaciones `$\{Y_1, Y_2, \ldots, Y_{T-m}\}$`, denotadas como datos de entrenamiento, y serán las observaciones que se emplearán para realizar la estimación del modelo y estimación de los pronósticos. El segundo grupo estará dado por las observaciones `$\{Y_{T-m+1}, Y_{T-m+2}, \ldots, Y_{T}\}$`, denotadas como datos de validación, y serán las observaciones que se emplearán para evaluar el desempeño de los modelos.

Entonces, suponga que a partir del conjunto de entrenamiento se realizan los pronósticos `$\{\hat{Y}_{T-m+1}, \hat{Y}_{T-m+2}, \ldots, \hat{Y}_{T}\}$`, entonces puede definirse el error de estimación `$e_t=\hat{varepsilon}_t$`, entre las observación real `$t$` y el valor pronosticado `$t$`, de la forma
`\begin{align*}
e_t= Y_t - \hat{Y}_t
\end{align*}`

con `$t={T-m+1}, {T-m+2}, \ldots, {T}$`. A partir de los errores de estimación `$e_t$`, es posible realizar el cálculo de diferentes medidas de error que permitan cuantificar diferentes aspectos de los valores pronosticados. Con el fin de ilustrar y mejorar el entendimiento de las medidas de error, se presentarán las propiedades que posee cada uno de ellos, basados en @Adhikari2013[, p. 42].

### Error medio (ME)
Esta medida está definida como
`\begin{align*}
ME=\frac{1}{m}\sum_{t=T-m+1}^T e_t 
\end{align*}`

* Es una medida de la desviación promedio de los valores pronosticados respecto a los valores reales.
* Muestra la dirección del error y, en consecuencia, el sesgo que poseen los pronóstico.
* En el ME, los efectos de los errores positivos y negativos se cancelan y no hay forma de saber su cantidad exacta.
* Un ME de cero no significa que los pronósticos sean perfectos o que no existan errores de pronóstico, si no que indica que los pronósticos no poseen ningún sesgo, y en consecuencia, están apuntancia hacia el objetivo correcto.
* El ME no penaliza los errores extremos de pronóstico.
* Depende de la escala de medición y también se ve afectada por las transformaciones de datos.
* Para que el pronostico sea bueno, se requiere que el sesgo sea mínimo, y por tanto, es deseable que el ME sea lo más cercano a cero posible.

```{r}
ME <- function(real, pred){
  mean(real - pred)
}
```


### Porcentaje medio del error (MPE)
Esta medida está definida como
`\begin{align*}
MPE=\frac{1}{m}\sum_{t=T-m+1}^T \frac{e_t}{y_t} \times 100
\end{align*}`

* Mode el porcentaje de error promedio ocurrido de los pronósticos.
* Muestra la dirección del error y, en consecuencia, el porcentaje de sesgo que poseen los pronóstico.
* En el MPE, los efectos de los errores positivos y negativos se cancelan mutuamente.
* El MPE es independiente de la escala de medición, pero se ve afectado por la transformación de datos.
* Similar al ME, el obtener valores de MPE cercanos a cero, no indican que los pronósticos sean buenos o que no existan errores de pronóstico, si no que indica que los pronosticos poseen un sesgo pequeño. 
* Similar al ME, es deseable que el sesgo del MPE sea mínimo, es decir, que el valor del MPE sea lo más pequeño posible.
* Al igual que el ME, el MPE no penaliza los errores extremos de pronóstico.

```{r}
MPE <- function(real, pred){
  mean((real - pred) / real) * 100
}
```


### Error absoluto medio (MAE)
Esta medida está definida como
`\begin{align*}
MAE=\frac{1}{m}\sum_{t=T-m+1}^T |e_t|
\end{align*}`

* Mide la desviación absoluta promedio de los valores pronosticados respecto a los valores reales.
* También se denomina como la desviación absoluta media (MAD).
* Muestra la magnitud del error general, ocurrido debido al pronóstico.
* A diferencia del ME, en el MAE, los efectos de los errores positivos y negativos no se anulan.
* A diferencia del ME, el MAE no proporciona ninguna idea sobre el sesgo de los pronósticos.
* Al igual que el ME, el MAE no penaliza los errores extremos de pronóstico.
* Al igual que el ME, el MAE también depende de la escala de medición y de las transformaciones de datos.
* Para que el pronostico sea bueno, se requiere que el MAE obtenido sea lo más pequeño posible.

```{r}
MAE <- function(real, pred){
  mean(abs(real - pred))
}
```


### Porcentaje del error medio absoluto (MAPE)
Esta medida está definida como
`\begin{align*}
MAPE=\frac{1}{m}\sum_{t=T-m+1}^T \left|\frac{e_t}{y_t}\right|\times 100
\end{align*}`

* Mide el porcentaje de error absoluto promedio ocurrido de los pronósticos.
* A diferencia del MPE, el MAPE no proporciona ninguna idea sobre el sesgo de los pronósticos.
* A diferencia del MPE, en el MAPE los efectos de los errores positivos y negativos no se anulan.
* Al igual que el MPE, el MAPE no penaliza los errores extremos de pronóstico.
* Al igual que el MPE, el MAPE también es independiente de la escala de medición, pero está afectado por la transformación de datos.

```{r}
MAPE <- function(real, pred){
  mean(abs((real - pred) / real)) * 100
}
```


### Error cuadrático medio (MSE)
Esta medida está definida como
`\begin{align*}
MSE=\frac{1}{m}\sum_{t=T-m+1}^T (e_t)^2
\end{align*}`

* Mide la desviación al cuadrado promedio de los valores pronosticados respecto a los valores reales.
* En el MSE, los errores positivos y negativos no se compensan entre si, y en consecuencia, el MSE proporciona una idea general del error ocurrido durante el pronóstico.
* A diferencia de las otras medidas, el MSE paneliza errores extremos ocurridos al pronosticar.
* El MSE enfatiza el hecho de que el error de pronóstico total está, de hecho, muy afectado por grandes errores individuales, es decir, los errores grandes son mucho más caros que los errores pequeños.
* A diferencia del ME y MPE, el MSE no proporciona ninguna idea sobre la dirección del error general, es decir, del sesgo de pronóstico.
* El MSE es sensible al cambio de escala y las transformaciones de datos.
* Aunque el MSE es una buena medida del error de pronóstico general, pero NO es tan intuitivo y fácilmente interpretable como las otras medidas discutidas anteriormente.

```{r}
MSE <- function(real, pred){
  mean((real - pred)^2)
}
```


### Suma de cuadrados del error (SSE)
Esta medida está definida como
`\begin{align*}
SSE=\sum_{t=T-m+1}^T (e_t)^2
\end{align*}`

* Posee las mismas propiedades del MSE.

```{r}
SSE <- function(real, pred){
  sum((real - pred)^2)
}
```


### Raíz cuadrada del error cuadrático medio (RMSE)
Esta medida está definida como
`\begin{align*}
RMSE=\sqrt{\frac{1}{m}\sum_{t=T-m+1}^T (e_t)^2}
\end{align*}`

* La RMSE no es más que la raíz cuadrada de la MSE calculada.
* Todas las demás propiedades de MSE se mantienen para RMSE también.

```{r}
RMSE <- function(real, pred){
  sqrt(mean((real - pred)^2))
}
```

## Función para calcular todas las medidas de error
```{r}
Med.error <- function(real, pred){
  me <- round(mean(real - pred), 4)
  mpe <- round(mean((real - pred) / real) * 100, 4)
  mae <- round(mean(abs(real - pred)), 4)
  mape <- round(mean(abs((real - pred) / real)) * 100, 4)
  mse <- round(mean((real - pred)^2), 4)
  sse <- round(sum((real - pred)^2), 4)
  rmse <- round(sqrt(mean((real - pred)^2)), 4)
  return(data.frame(ME = me, MPE = paste0(mpe, "%"), MAE = mae,
                    MAPE = paste0(mape, "%"), MSE = mse, SSE = sse, RMSE = rmse))
}
```


## Bibliografía


